{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pefile, fnmatch, os, time, pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from multiprocessing import Pool\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "import xgboost as xgb\n",
    "from xgboost import cv, DMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_headers(pe):\n",
    "    headers = {\n",
    "        'OH.SizeOfCode'                 :pe.OPTIONAL_HEADER.SizeOfCode,\n",
    "        'OH.SizeOfInitializedData'      :pe.OPTIONAL_HEADER.SizeOfInitializedData,\n",
    "        'OH.AddressOfEntryPoint'        :pe.OPTIONAL_HEADER.AddressOfEntryPoint,\n",
    "        'OH.BaseOfCode'                 :pe.OPTIONAL_HEADER.BaseOfCode,\n",
    "        'OH.BaseOfData'                 :pe.OPTIONAL_HEADER.BaseOfData,\n",
    "        'OH.ImageBase'                  :pe.OPTIONAL_HEADER.ImageBase,\n",
    "        'OH.MajorOperatingSystemVersion':pe.OPTIONAL_HEADER.MajorOperatingSystemVersion,\n",
    "        'OH.MajorSubsystemVersion'      :pe.OPTIONAL_HEADER.MajorSubsystemVersion,\n",
    "        'OH.SizeOfImage'                :pe.OPTIONAL_HEADER.SizeOfImage,\n",
    "        'OH.SizeOfHeaders'              :pe.OPTIONAL_HEADER.SizeOfHeaders,\n",
    "        'OH.CheckSum'                   :pe.OPTIONAL_HEADER.CheckSum,\n",
    "        'OH.Subsystem'                  :pe.OPTIONAL_HEADER.Subsystem,\n",
    "        'OH.DllCharacteristics'         :pe.OPTIONAL_HEADER.DllCharacteristics,\n",
    "        'OH.SizeOfStackReserve'         :pe.OPTIONAL_HEADER.SizeOfStackReserve,\n",
    "        'OH.SizeOfStackCommit'          :pe.OPTIONAL_HEADER.SizeOfStackCommit,\n",
    "        'OH.SizeOfHeapReserve'          :pe.OPTIONAL_HEADER.SizeOfHeapReserve,\n",
    "        'OH.SizeOfHeapCommit'           :pe.OPTIONAL_HEADER.SizeOfHeapCommit,\n",
    "\n",
    "        'FH.NumberOfSections'           :pe.FILE_HEADER.NumberOfSections,\n",
    "        'FH.TimeDateStamp'              :pe.FILE_HEADER.TimeDateStamp,\n",
    "        'FH.Characteristics'            :pe.FILE_HEADER.Characteristics,\n",
    "    }\n",
    "    return headers\n",
    "\n",
    "def parse_sections(pe):\n",
    "    sections = []\n",
    "    for entry in pe.sections:\n",
    "        sect = {\n",
    "            'SectionName'   :str(entry.Name),\n",
    "            'SectionSize'   :hex(entry.SizeOfRawData),\n",
    "            'SectionEntropy':entry.get_entropy()\n",
    "            }\n",
    "        sections.append(sect)\n",
    "    return sections\n",
    "\n",
    "def parse_import(pe):\n",
    "    import_table = list()\n",
    "    import_num = 0\n",
    "    dll_num = 0\n",
    "    if hasattr(pe, 'DIRECTORY_ENTRY_IMPORT'):\n",
    "        dll_num = len(pe.DIRECTORY_ENTRY_IMPORT)\n",
    "        for entry in pe.DIRECTORY_ENTRY_IMPORT:\n",
    "            import_entry = dict()\n",
    "            import_entry['dll'] = entry.dll\n",
    "            import_entry['symbols'] = list()\n",
    "            import_num = import_num + len(entry.imports)\n",
    "            for imp in entry.imports:\n",
    "                import_entry['symbols'].append(imp.name)\n",
    "            import_table.append(import_entry)\n",
    "    return import_table, import_num, dll_num\n",
    "\n",
    "def parse_export(pe):\n",
    "    if hasattr(pe, 'DIRECTORY_ENTRY_EXPORT'):\n",
    "        return len(pe.DIRECTORY_ENTRY_EXPORT.symbols)\n",
    "    return 0\n",
    "\n",
    "def size(name): return os.path.getsize(name)\n",
    "\n",
    "def parse_pe(name):\n",
    "    try:\n",
    "        pe = pefile.PE(name)\n",
    "        info = parse_headers(pe)\n",
    "        info['sections'] = parse_sections(pe)\n",
    "        info['export_num'] = parse_export(pe)\n",
    "        info['import'], info['import_num'], info['dll_num'] = parse_import(pe)\n",
    "        pe.close()\n",
    "        info['sha256'] = name.split('\\\\')[-1]\n",
    "        info['size'] = size(name)\n",
    "        return info\n",
    "    except Exception:\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "def find_files(directory, pattern):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for basename in files:\n",
    "            if fnmatch.fnmatch(basename, pattern):\n",
    "                filename = os.path.join(root, basename)\n",
    "                yield filename\n",
    "\n",
    "def enum_pe(type, path):\n",
    "    pool = Pool()\n",
    "    results = [pool.apply_async(parse_pe, (filename,)) for filename in find_files(path, '*')]\n",
    "    files = list()\n",
    "    for result in results:\n",
    "        result.wait()\n",
    "        try:\n",
    "            info = result.get()\n",
    "        except:\n",
    "            continue\n",
    "        if info != None:\n",
    "            info['type'] = type\n",
    "            files.append(info)\n",
    "    pool.terminate()\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type\n",
      "malware    198\n",
      "normal     422\n",
      "Name: sha256, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "files = enum_pe('malware', 'malware') + enum_pe('normal', 'normal')\n",
    "\n",
    "df = pd.DataFrame(files)\n",
    "\n",
    "files.clear()\n",
    "\n",
    "print(df.groupby('type')['sha256'].count())\n",
    "print()\n",
    "\n",
    "df.to_csv('features.csv', sep=';', index=False)\n",
    "df = df.drop(['sha256', 'size'], axis=1)\n",
    "\n",
    "sections = df['sections'].apply(pd.Series).stack().reset_index(level=1, drop=True).apply(pd.Series)\n",
    "\n",
    "imports = df['import'].apply(pd.Series).stack().reset_index(level=1, drop=True).apply(pd.Series)\n",
    "imports = imports.reset_index().set_index(['index', 'dll'])\n",
    "imports = imports['symbols'].apply(pd.Series).stack().reset_index(level=2, drop=True).to_frame('import').reset_index().set_index('index')\n",
    "\n",
    "join = sections.join(imports).fillna(0)\n",
    "\n",
    "join['SectionName'] = join['SectionName'].astype('str')\n",
    "join['dll'] = join['dll'].astype('str')\n",
    "join['import'] = join['import'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_columns = ['SectionName', 'dll', 'import']\n",
    "ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "matrix = ohe.fit_transform(join[string_columns])\n",
    "index = join.index\n",
    "rows = []\n",
    "for i in index.unique():\n",
    "    select = index.slice_indexer(start=i, end=i)\n",
    "    rows.append(csr_matrix(matrix[select].sum(axis=0)))\n",
    "\n",
    "join_encoded = pd.DataFrame(data={'matrix':rows})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['sections', 'import'], axis=1)\n",
    "df = df.join(join_encoded)\n",
    "\n",
    "y = df['type'] == 'malware'\n",
    "\n",
    "X = df.drop('type', axis=1)\n",
    "X = X.apply(lambda x: hstack((x.drop('matrix').astype('int64').values, x['matrix'])).T, axis=1)\n",
    "X = hstack(X.values).T\n",
    "X = X.todok().toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nsuprotivniy/.local/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/nsuprotivniy/.local/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    }
   ],
   "source": [
    "dtrain = DMatrix(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'max_depth': 6\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-auc-mean</th>\n",
       "      <th>train-auc-std</th>\n",
       "      <th>test-auc-mean</th>\n",
       "      <th>test-auc-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.994777</td>\n",
       "      <td>0.003703</td>\n",
       "      <td>0.982244</td>\n",
       "      <td>0.013750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.992187</td>\n",
       "      <td>0.007615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.992187</td>\n",
       "      <td>0.007615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.993258</td>\n",
       "      <td>0.008153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.993311</td>\n",
       "      <td>0.008189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.993273</td>\n",
       "      <td>0.008241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.993348</td>\n",
       "      <td>0.008136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.993365</td>\n",
       "      <td>0.008147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.993366</td>\n",
       "      <td>0.008111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.993366</td>\n",
       "      <td>0.008111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train-auc-mean  train-auc-std  test-auc-mean  test-auc-std\n",
       "0        0.994777       0.003703       0.982244      0.013750\n",
       "1        1.000000       0.000000       0.992187      0.007615\n",
       "2        1.000000       0.000000       0.992187      0.007615\n",
       "3        1.000000       0.000000       0.993258      0.008153\n",
       "4        1.000000       0.000000       0.993311      0.008189\n",
       "5        1.000000       0.000000       0.993273      0.008241\n",
       "6        1.000000       0.000000       0.993348      0.008136\n",
       "7        1.000000       0.000000       0.993365      0.008147\n",
       "8        1.000000       0.000000       0.993366      0.008111\n",
       "9        1.000000       0.000000       0.993366      0.008111"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv(params=params, dtrain=dtrain, metrics=\"auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "booster = xgb.train(params=params, dtrain=dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model.pickle\", \"wb\") as f:\n",
    "    pickle.dump(booster, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ohe.pickle\", \"wb\") as f:\n",
    "    pickle.dump(ohe, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [parse_pe('malware/0cf176827f89ff5167319c15aba7c74d176b0f93dd42f383567faa6c5af2ef21')]\n",
    "df = pd.DataFrame(files)\n",
    "df = df.drop(['sha256', 'size'], axis=1)\n",
    "sections = df['sections'].apply(pd.Series).stack().reset_index(level=1, drop=True).apply(pd.Series)\n",
    "\n",
    "imports = df['import'].apply(pd.Series).stack().reset_index(level=1, drop=True).apply(pd.Series)\n",
    "imports = imports.reset_index().set_index(['index', 'dll'])\n",
    "imports = imports['symbols'].apply(pd.Series).stack().reset_index(level=2, drop=True).to_frame('import').reset_index().set_index('index')\n",
    "\n",
    "join = sections.join(imports).fillna(0)\n",
    "\n",
    "join['SectionName'] = join['SectionName'].astype('str')\n",
    "join['dll'] = join['dll'].astype('str')\n",
    "join['import'] = join['import'].astype('str')\n",
    "\n",
    "string_columns = ['SectionName', 'dll', 'import']\n",
    "encoders = {}\n",
    "for col in string_columns:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(join[col])\n",
    "    encoders[col] = le\n",
    "    join[col] = le.transform(join[col])\n",
    "\n",
    "matrix = ohe.transform(join)\n",
    "\n",
    "index = join.index\n",
    "rows = []\n",
    "for i in index.unique():\n",
    "    select = index.slice_indexer(start=i, end=i)\n",
    "    rows.append(csr_matrix(matrix[select].sum(axis=0)))\n",
    "\n",
    "join_encoded = pd.DataFrame(data={'matrix':rows})\n",
    "\n",
    "df = df.drop(['sections', 'import'], axis=1)\n",
    "df = df.join(join_encoded)\n",
    "\n",
    "X = df.apply(lambda x: hstack((x.drop('matrix').astype('int64').values, x['matrix'])).T, axis=1)\n",
    "X = hstack(X.values).T\n",
    "X = X.todok().toarray()\n",
    "booster.predict(DMatrix(X))[0] > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
